{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e2bd10",
   "metadata": {},
   "source": [
    "# Spam Filtering Binary Classification\n",
    "\n",
    "- https://www.kaggle.com/uciml/sms-spam-collection-dataset  \n",
    "\n",
    "- SMS 스팸 컬렉션은 태그가 지정된 SMS 메시지 집합입니다. 여기에는 5,574 개 메시지 중 영어로 된 SMS 메시지 한 세트가 포함되어 있으며 이에 따라 햄 (합법적) 또는 스팸으로 태그가 지정됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d885c",
   "metadata": {},
   "source": [
    "- label value 는 spam, ham 두가지  \n",
    "- ham 은 0, spam 은 1 로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442db26a",
   "metadata": {},
   "source": [
    "### Train / Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9aeb8",
   "metadata": {},
   "source": [
    "### Create Document Train Matrix (Bag of Word)\n",
    "\n",
    "Bag of Words란 단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법입니다. 텍스트 문서에 있는 단어들을 가방에다가 전부 넣습니다. 그러고나서 이 가방을 흔들어 단어들을 섞습니다. 만약, 해당 문서 내에서 특정 단어가 N번 등장했다면, 이 가방에는 그 특정 단어가 N개 있게됩니다. 또한 가방을 흔들어서 단어를 섞었기 때문에 더 이상 단어의 순서는 중요하지 않습니다.\n",
    "\n",
    "- BoW를 만드는 과정.  \n",
    "(1) 각 단어에 고유한 정수 인덱스를 부여합니다.  \n",
    "(2) 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만듭니다.\n",
    "\n",
    "\n",
    "- 문장을 token화 하고 각 문장에 token 이 몇 번 등장하는지 count  \n",
    "\n",
    "- 각 token 을 feature 화하여 feature(단어) 출현 횟수에 따라 spam 여부 분류\n",
    "\n",
    "- CountVectorizer\n",
    "    - min_df : vocabulary 에 포함할 최소 발생 빈도\n",
    "    - ngram_range : (1, 1) - unigram only, (1, 2) - unigram + bigram\n",
    "    - max_features : top max_features 만으로 vocabulary 구성\n",
    "    - token_pattern = (?u)\\\\b\\\\w\\\\w+\\\\b : unocode 영수자 2 글자 이상만 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b587f0",
   "metadata": {},
   "source": [
    "### Tokenized Train document matrix  생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf75f4bf",
   "metadata": {},
   "source": [
    "- test data 는 train data 에서 fit 한 count vectorizer 를 이용하여 transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f1e17",
   "metadata": {},
   "source": [
    "### 이진 분류기 train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829a7c67",
   "metadata": {},
   "source": [
    "### predict\n",
    "\n",
    "- `predict()` - 예측된 class 를 threshold 0.5 기준으로 반환\n",
    "- `predict_proba()` - class 별 probability 를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037e0bc7",
   "metadata": {},
   "source": [
    "## confusion matrix 를 이용한 model 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492135d",
   "metadata": {},
   "source": [
    "# 2. SVM (Support Vector Machine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
